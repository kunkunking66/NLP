{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "print(common_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 20:15:48,734 : INFO : collecting all words and their counts\n",
      "2024-10-22 20:15:48,735 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-10-22 20:15:48,736 : INFO : collected 12 word types and 9 unique tags from a corpus of 9 examples and 29 words\n",
      "2024-10-22 20:15:48,736 : INFO : Creating a fresh vocabulary\n",
      "2024-10-22 20:15:48,736 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 12 unique words (100.00% of original 12, drops 0)', 'datetime': '2024-10-22T20:15:48.736941', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-22 20:15:48,737 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 29 word corpus (100.00% of original 29, drops 0)', 'datetime': '2024-10-22T20:15:48.737274', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-22 20:15:48,737 : INFO : deleting the raw counts dictionary of 12 items\n",
      "2024-10-22 20:15:48,737 : INFO : sample=0.001 downsamples 12 most-common words\n",
      "2024-10-22 20:15:48,738 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 3.5001157321504532 word corpus (12.1%% of prior 29)', 'datetime': '2024-10-22T20:15:48.738093', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-22 20:15:48,738 : INFO : estimated required memory for 12 words and 5 dimensions: 8460 bytes\n",
      "2024-10-22 20:15:48,739 : INFO : resetting layer weights\n",
      "2024-10-22 20:15:48,739 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 12 vocabulary and 5 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-10-22T20:15:48.739878', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-10-22 20:15:48,742 : INFO : EPOCH 0: training on 29 raw words (13 effective words) took 0.0s, 131369 effective words/s\n",
      "2024-10-22 20:15:48,743 : INFO : EPOCH 1: training on 29 raw words (12 effective words) took 0.0s, 59065 effective words/s\n",
      "2024-10-22 20:15:48,745 : INFO : EPOCH 2: training on 29 raw words (11 effective words) took 0.0s, 25478 effective words/s\n",
      "2024-10-22 20:15:48,747 : INFO : EPOCH 3: training on 29 raw words (9 effective words) took 0.0s, 32009 effective words/s\n",
      "2024-10-22 20:15:48,748 : INFO : EPOCH 4: training on 29 raw words (15 effective words) took 0.0s, 159433 effective words/s\n",
      "2024-10-22 20:15:48,749 : INFO : EPOCH 5: training on 29 raw words (13 effective words) took 0.0s, 57628 effective words/s\n",
      "2024-10-22 20:15:48,750 : INFO : EPOCH 6: training on 29 raw words (12 effective words) took 0.0s, 53691 effective words/s\n",
      "2024-10-22 20:15:48,752 : INFO : EPOCH 7: training on 29 raw words (12 effective words) took 0.0s, 38767 effective words/s\n",
      "2024-10-22 20:15:48,753 : INFO : EPOCH 8: training on 29 raw words (13 effective words) took 0.0s, 50477 effective words/s\n",
      "2024-10-22 20:15:48,754 : INFO : EPOCH 9: training on 29 raw words (9 effective words) took 0.0s, 605039 effective words/s\n",
      "2024-10-22 20:15:48,755 : INFO : Doc2Vec lifecycle event {'msg': 'training on 290 raw words (119 effective words) took 0.0s, 7905 effective words/s', 'datetime': '2024-10-22T20:15:48.755148', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-10-22 20:15:48,755 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d5,n5,w2,s0.001,t3>', 'datetime': '2024-10-22T20:15:48.755529', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# 拼接数据\n",
    "documents = [TaggedDocument(doc, [i]) for i,doc in enumerate(common_texts)]\n",
    "# 模型训练\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doc2Vec 是 Gensim 提供的一个类，用于训练 Doc2Vec 模型。\n",
    "- documents 是一个包含标记文档的列表。\n",
    "- vector_size=5：设置文档向量的维度大小为 5。\n",
    "- window=2：设置窗口大小为 2，即在训练过程中考虑目标词周围 2 个词的上下文。\n",
    "- min_count=1：忽略所有在文档中出现次数少于 1 次的单词。\n",
    "- workers=3：设置并行工作的线程数为 3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Doc2Vec结果】:\n",
      "[ 0.00097145  0.08869147  0.07331518  0.03625821 -0.06569277]\n"
     ]
    }
   ],
   "source": [
    "# 预测文本对应向量的时候，实际上是基于训练好的单词向量(冻结固定)，然后反向传播更新待预测文本/文档对应的特征向量\n",
    "vector = model.infer_vector([\"system\", \"response\"])\n",
    "print(\"【Doc2Vec结果】:\\n{}\".format(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human', 'interface', 'computer']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07681892, 0.06059645, 0.06680731, 0.05171209, 0.08656023],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector(common_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、FastText\n",
    "\n",
    "FastText 在词嵌入领域非常有名，因为它不仅能够为每个单词创建向量表示，还能处理那些在训练集中未曾见过的单词（通过组合单词内的字符 n-gram 向量）。这种方法对于处理生僻词汇或拼写错误特别有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 09:46:58,213 : INFO : collecting all words and their counts\n",
      "2024-10-23 09:46:58,216 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-10-23 09:46:58,275 : INFO : collected 17807 word types from a corpus of 131945 raw words and 2421 sentences\n",
      "2024-10-23 09:46:58,276 : INFO : Creating a fresh vocabulary\n",
      "2024-10-23 09:46:58,301 : INFO : FastText lifecycle event {'msg': 'effective_min_count=1 retains 17807 unique words (100.00% of original 17807, drops 0)', 'datetime': '2024-10-23T09:46:58.301369', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-23 09:46:58,302 : INFO : FastText lifecycle event {'msg': 'effective_min_count=1 leaves 131945 word corpus (100.00% of original 131945, drops 0)', 'datetime': '2024-10-23T09:46:58.302174', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-23 09:46:58,331 : INFO : deleting the raw counts dictionary of 17807 items\n",
      "2024-10-23 09:46:58,332 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2024-10-23 09:46:58,333 : INFO : FastText lifecycle event {'msg': 'downsampling leaves estimated 111167.11834424097 word corpus (84.3%% of prior 131945)', 'datetime': '2024-10-23T09:46:58.333038', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-10-23 09:46:58,393 : INFO : estimated required memory for 17807 words, 2000000 buckets and 4 dimensions: 43549136 bytes\n",
      "2024-10-23 09:46:58,393 : INFO : resetting layer weights\n",
      "2024-10-23 09:46:58,490 : INFO : FastText lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-10-23T09:46:58.490113', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'build_vocab'}\n",
      "2024-10-23 09:46:58,490 : INFO : FastText lifecycle event {'msg': 'training model with 3 workers on 17807 vocabulary and 4 features, using sg=0 hs=0 sample=0.001 negative=5 window=3 shrink_windows=True', 'datetime': '2024-10-23T09:46:58.490533', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-10-23 09:46:58,559 : INFO : EPOCH 0: training on 131945 raw words (111160 effective words) took 0.1s, 1645431 effective words/s\n",
      "2024-10-23 09:46:58,623 : INFO : EPOCH 1: training on 131945 raw words (110970 effective words) took 0.1s, 1752096 effective words/s\n",
      "2024-10-23 09:46:58,687 : INFO : EPOCH 2: training on 131945 raw words (111166 effective words) took 0.1s, 1754816 effective words/s\n",
      "2024-10-23 09:46:58,751 : INFO : EPOCH 3: training on 131945 raw words (111204 effective words) took 0.1s, 1784102 effective words/s\n",
      "2024-10-23 09:46:58,814 : INFO : EPOCH 4: training on 131945 raw words (111128 effective words) took 0.1s, 1766351 effective words/s\n",
      "2024-10-23 09:46:58,880 : INFO : EPOCH 5: training on 131945 raw words (111313 effective words) took 0.1s, 1716807 effective words/s\n",
      "2024-10-23 09:46:58,947 : INFO : EPOCH 6: training on 131945 raw words (111306 effective words) took 0.1s, 1682863 effective words/s\n",
      "2024-10-23 09:46:59,013 : INFO : EPOCH 7: training on 131945 raw words (111111 effective words) took 0.1s, 1693200 effective words/s\n",
      "2024-10-23 09:46:59,087 : INFO : EPOCH 8: training on 131945 raw words (111290 effective words) took 0.1s, 1541612 effective words/s\n",
      "2024-10-23 09:46:59,163 : INFO : EPOCH 9: training on 131945 raw words (111096 effective words) took 0.1s, 1472019 effective words/s\n",
      "2024-10-23 09:46:59,163 : INFO : FastText lifecycle event {'msg': 'training on 1319450 raw words (1111744 effective words) took 0.7s, 1651517 effective words/s', 'datetime': '2024-10-23T09:46:59.163919', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-10-23 09:46:59,223 : INFO : FastText lifecycle event {'params': 'FastText<vocab=17807, vector_size=4, alpha=0.025>', 'datetime': '2024-10-23T09:46:59.223380', 'gensim': '4.3.3', 'python': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'platform': 'macOS-14.4-arm64-arm-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim import utils\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "word_file_path = './datas/cut_words_of_in_the_name_of_people.txt'\n",
    "class MyData(object):\n",
    "    def __iter__(self):\n",
    "        path = word_file_path\n",
    "        with open(path, 'r', encoding='utf-8') as reader:\n",
    "            for line in reader:\n",
    "                yield list(utils.tokenize(line))\n",
    "\n",
    "# 模型构建\n",
    "model = FastText(vector_size=4, window=3, min_count=1, sentences=MyData(), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Here', 'is', 'an', 'example', 'sentence', 'to', 'be', 'tokenized']\n"
     ]
    }
   ],
   "source": [
    "# 假设这是你从文件中读取的一行文本\n",
    "line = \"Here is an example sentence to be tokenized.\"\n",
    "\n",
    "# 使用 gensim 的 simple_preprocess 方法来分词\n",
    "tokens = list(utils.tokenize(line))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __iter__ 方法告诉 Python 解释器这个类的对象可以被迭代。当一个对象被称为“可迭代”时，意味着你可以用 for 循环来遍历它。\n",
    "- yield 关键字用于定义生成器。每当迭代到这一行时，函数会暂停并发送给调用者一个值（这里是 list(utils.tokenize(line))），然后保留当前状态，直到下次迭代时从 yield 表达式后继续执行。utils.tokenize(line) 是一个工具方法，用于将输入的字符串 line 分割成词汇列表。结果会被转换成列表类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "红了眼 0.9998026490211487\n",
      "戏剧性 0.9992764592170715\n",
      "最合适 0.9986774325370789\n",
      "没良心 0.9985163807868958\n",
      "好莱坞 0.9985069632530212\n"
     ]
    }
   ],
   "source": [
    "# 夹角余弦相似度\n",
    "req_count = 5\n",
    "for key in model.wv.similar_by_word('沙瑞金', topn =100):\n",
    "    if len(key[0])==3:\n",
    "        req_count -= 1\n",
    "        print(key[0], key[1])\n",
    "        if req_count == 0:\n",
    "            break;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
