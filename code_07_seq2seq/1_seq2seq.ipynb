{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:44:17.634813Z",
     "start_time": "2025-01-14T01:44:15.137071Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.random.manual_seed(0)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24fa34473f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EncoderModule"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:44:20.420547Z",
     "start_time": "2025-01-14T01:44:20.415167Z"
    }
   },
   "source": [
    "class EncoderModule(nn.Module):\n",
    "    # 将vocab_size这么多维度降维到embedding_dim\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size=None, num_layers=1, bidirectional=False):\n",
    "        # 调用父类nn.Module\n",
    "        super(EncoderModule, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        hidden_size = hidden_size or embedding_dim\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Linear(in_features=embedding_dim, out_features=hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_dim = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        编码器前向过程\n",
    "        :param x: [N,T] token id tensor对象\n",
    "        :return: [N,L] 向量矩阵，针对每个文本用一个L维的向量进行表示\n",
    "        \"\"\"\n",
    "        x = self.embedding_layer(x)  # [N,T] -> [N,T,E]\n",
    "        hn = self.features(x)  # hn [N,T,E] -> [N,T,hidden_size]\n",
    "        hz = torch.mean(hn, dim=1)  # [N,T,hidden_size] -> [N,hidden_size]\n",
    "        return hz\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T01:44:23.769672Z",
     "start_time": "2025-01-14T01:44:23.709538Z"
    }
   },
   "source": [
    "net = EncoderModule(vocab_size=100, embedding_dim=3, num_layers=2, bidirectional=True)\n",
    "x = torch.randint(50, size=(2, 4))\n",
    "c = net(x)\n",
    "print(c.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### onnx"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T02:04:27.559366Z",
     "start_time": "2025-01-14T02:04:27.443236Z"
    }
   },
   "source": [
    "import torch.onnx\n",
    "# import netron\n",
    "\n",
    "# 设置模型为评估模式\n",
    "net.eval()\n",
    "\n",
    "# 创建示例输入\n",
    "dummy_input = torch.randint(50, size=(2, 4))\n",
    "\n",
    "# 导出模型为 ONNX 格式\n",
    "output_file = \"encoder_model.onnx\"\n",
    "torch.onnx.export(net, dummy_input, output_file,\n",
    "                  export_params=True,        # 存储训练过的参数\n",
    "                  opset_version=10,         # ONNX 版本\n",
    "                  do_constant_folding=True, # 是否执行常量折叠优化\n",
    "                  input_names=['input'],    # 输入名称\n",
    "                  output_names=['output'],  # 输出名称\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}} # 批次大小动态\n",
    "                  )\n",
    "\n",
    "# print(f\"ONNX model exported to {output_file}\")\n",
    "\n",
    "# # 使用 netron 查看 ONNX 模型\n",
    "# netron.start(output_file)"
   ],
   "outputs": [
    {
     "ename": "OnnxExporterError",
     "evalue": "Module onnx is not installed!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\onnx\\_internal\\onnx_proto_utils.py:220\u001B[0m, in \u001B[0;36m_add_onnxscript_fn\u001B[1;34m(model_bytes, custom_opsets)\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 220\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'onnx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mOnnxExporterError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# 导出模型为 ONNX 格式\u001B[39;00m\n\u001B[0;32m     11\u001B[0m output_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mencoder_model.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 12\u001B[0m torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mexport(net, dummy_input, output_file,\n\u001B[0;32m     13\u001B[0m                   export_params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,        \u001B[38;5;66;03m# 存储训练过的参数\u001B[39;00m\n\u001B[0;32m     14\u001B[0m                   opset_version\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,         \u001B[38;5;66;03m# ONNX 版本\u001B[39;00m\n\u001B[0;32m     15\u001B[0m                   do_constant_folding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;66;03m# 是否执行常量折叠优化\u001B[39;00m\n\u001B[0;32m     16\u001B[0m                   input_names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m],    \u001B[38;5;66;03m# 输入名称\u001B[39;00m\n\u001B[0;32m     17\u001B[0m                   output_names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput\u001B[39m\u001B[38;5;124m'\u001B[39m],  \u001B[38;5;66;03m# 输出名称\u001B[39;00m\n\u001B[0;32m     18\u001B[0m                   dynamic_axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;241m0\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m}, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;241m0\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m}} \u001B[38;5;66;03m# 批次大小动态\u001B[39;00m\n\u001B[0;32m     19\u001B[0m                   )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\onnx\\utils.py:551\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining, dynamo)\u001B[0m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    547\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    548\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExport destination must be specified for torchscript-onnx export.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    549\u001B[0m     )\n\u001B[1;32m--> 551\u001B[0m _export(\n\u001B[0;32m    552\u001B[0m     model,\n\u001B[0;32m    553\u001B[0m     args,\n\u001B[0;32m    554\u001B[0m     f,\n\u001B[0;32m    555\u001B[0m     export_params,\n\u001B[0;32m    556\u001B[0m     verbose,\n\u001B[0;32m    557\u001B[0m     training,\n\u001B[0;32m    558\u001B[0m     input_names,\n\u001B[0;32m    559\u001B[0m     output_names,\n\u001B[0;32m    560\u001B[0m     operator_export_type\u001B[38;5;241m=\u001B[39moperator_export_type,\n\u001B[0;32m    561\u001B[0m     opset_version\u001B[38;5;241m=\u001B[39mopset_version,\n\u001B[0;32m    562\u001B[0m     do_constant_folding\u001B[38;5;241m=\u001B[39mdo_constant_folding,\n\u001B[0;32m    563\u001B[0m     dynamic_axes\u001B[38;5;241m=\u001B[39mdynamic_axes,\n\u001B[0;32m    564\u001B[0m     keep_initializers_as_inputs\u001B[38;5;241m=\u001B[39mkeep_initializers_as_inputs,\n\u001B[0;32m    565\u001B[0m     custom_opsets\u001B[38;5;241m=\u001B[39mcustom_opsets,\n\u001B[0;32m    566\u001B[0m     export_modules_as_functions\u001B[38;5;241m=\u001B[39mexport_modules_as_functions,\n\u001B[0;32m    567\u001B[0m     autograd_inlining\u001B[38;5;241m=\u001B[39mautograd_inlining,\n\u001B[0;32m    568\u001B[0m )\n\u001B[0;32m    570\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\onnx\\utils.py:1722\u001B[0m, in \u001B[0;36m_export\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001B[0m\n\u001B[0;32m   1703\u001B[0m     (\n\u001B[0;32m   1704\u001B[0m         proto,\n\u001B[0;32m   1705\u001B[0m         export_map,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1719\u001B[0m         node_attr_to_name,\n\u001B[0;32m   1720\u001B[0m     )\n\u001B[0;32m   1721\u001B[0m \u001B[38;5;66;03m# insert function_proto into model_proto.\u001B[39;00m\n\u001B[1;32m-> 1722\u001B[0m proto \u001B[38;5;241m=\u001B[39m onnx_proto_utils\u001B[38;5;241m.\u001B[39m_add_onnxscript_fn(\n\u001B[0;32m   1723\u001B[0m     proto,\n\u001B[0;32m   1724\u001B[0m     custom_opsets,\n\u001B[0;32m   1725\u001B[0m )\n\u001B[0;32m   1726\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[0;32m   1727\u001B[0m     torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExported graph: \u001B[39m\u001B[38;5;124m\"\u001B[39m, graph)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\onnx\\_internal\\onnx_proto_utils.py:222\u001B[0m, in \u001B[0;36m_add_onnxscript_fn\u001B[1;34m(model_bytes, custom_opsets)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 222\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOnnxExporterError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModule onnx is not installed!\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;66;03m# For > 2GB model, onnx.load_fromstring would fail. However, because\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;66;03m# in _export_onnx, the tensors should be saved separately if the proto\u001B[39;00m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;66;03m# size > 2GB, and if it for some reason did not, the model would fail on\u001B[39;00m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;66;03m# serialization anyway in terms of the protobuf limitation. So we don't\u001B[39;00m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;66;03m# need to worry about > 2GB model getting here.\u001B[39;00m\n\u001B[0;32m    229\u001B[0m model_proto \u001B[38;5;241m=\u001B[39m onnx\u001B[38;5;241m.\u001B[39mload_model_from_string(model_bytes)  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
      "\u001B[1;31mOnnxExporterError\u001B[0m: Module onnx is not installed!"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecoderModule"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T02:12:30.739177Z",
     "start_time": "2025-01-14T02:12:30.728937Z"
    }
   },
   "source": [
    "class DecoderModule(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size, embedding_dim, encoder_state_dim,\n",
    "                 hidden_size=None, num_layers=1, eos_token_id=0, max_seq_length=20\n",
    "                 ):\n",
    "        super(DecoderModule, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.hidden_size = hidden_size or embedding_dim\n",
    "        assert num_layers == 1, \"当前解码器仅支持单层结构!\"\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn_state_proj = nn.Sequential(\n",
    "            nn.Linear(in_features=encoder_state_dim, out_features=self.hidden_size * self.num_layers),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=embedding_dim, hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers, batch_first=True, bidirectional=False\n",
    "        )\n",
    "        # 当前模拟代码中，类别数目和词汇表数目一致\n",
    "        self.proj = nn.Linear(\n",
    "            in_features=self.hidden_size,\n",
    "            out_features=vocab_size\n",
    "        )\n",
    "        # 解码器属性\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.eos_token_id = eos_token_id\n",
    "        self.rnn_cell = nn.RNNCell(input_size=embedding_dim, hidden_size=self.hidden_size)\n",
    "        self.rnn_cell.weight_ih = self.rnn.weight_ih_l0\n",
    "        self.rnn_cell.weight_hh = self.rnn.weight_hh_l0\n",
    "        self.rnn_cell.bias_ih = self.rnn.bias_ih_l0\n",
    "        self.rnn_cell.bias_hh = self.rnn.bias_hh_l0\n",
    "\n",
    "    def forward(self, x, encoder_state):\n",
    "        \"\"\"\n",
    "        解码器的前向过程\n",
    "        :param x: [N,T] 训练的时候，是token id列表，T为实际长度；预测的时候T为1\n",
    "        :param encoder_state: [N,encoder_state_dim] 解码器的初始状态信息 ---> 一般来源于编码器的输出\n",
    "        :return: [N,T,vocab_size] N个文本，对应T个时刻，每个时刻预测的类别置信度值\n",
    "            NOTE: 训练的时候返回值中的T和x中的T一致，推理预测的时候不一致\n",
    "        \"\"\"\n",
    "        # 将编码器传递过来的状态信息进行转换，作为解码器的初始状态信息\n",
    "        init_state = self.rnn_state_proj(encoder_state)  # [N,encoder_state_dim] -> [N,hidden_size*num_layers]\n",
    "        init_state = torch.reshape(init_state, shape=(-1, self.hidden_size, self.num_layers))\n",
    "        init_state = torch.permute(init_state, dims=[2, 0, 1])   # [num_layers,N,hidden_size]符合rnn hn的输入要求\n",
    "\n",
    "        # embedding操作\n",
    "        x = self.embedding_layer(x)  # [N,T] -> [N,T,E]\n",
    "\n",
    "        if self.training:\n",
    "            # print (\"model is in train mode\")\n",
    "            output, _ = self.rnn(x, init_state)  # output -> [n,T,hidden_size]\n",
    "            scores = self.proj(output)  # [n,T,vocab_size]\n",
    "            return scores\n",
    "        else:\n",
    "            # print (\"model is in eval mode\")\n",
    "            # 需要进行遍历操作，每个时刻每个时刻进行预测，直到预测结果为eos_token_id或者预测的序列长度超过阈值的时候，结束预测\n",
    "            outputs = []\n",
    "            hx = init_state[0]  # 第一层的rnn的状态信息\n",
    "            xi = x[:, 0, :]     # 第一个时刻的输入\n",
    "            n, _ = xi.shape     # n为batch_size\n",
    "            eos_token_ids, is_eos = None, None\n",
    "            while len(outputs) < self.max_seq_length:\n",
    "                # 当前rnn的输入: x和状态信息 --> 获取当前rnn的输出\n",
    "                hx = self.rnn_cell(xi, hx)  # [N,hidden_size]\n",
    "                oi = hx  # RNN的状态信息就是输出信息\n",
    "\n",
    "                # 进一步的特征提取转换，获取当前时刻的预测token id\n",
    "                scores_i = self.proj(oi)  # 得到当前时刻的预测置信度 [N,hidden_size] ->  [N,vocab_size]\n",
    "                token_ids_i = torch.argmax(scores_i, dim=1, keepdim=True)  # 当前预测id [N, 1]\n",
    "                outputs.append(token_ids_i)\n",
    "\n",
    "                # 判断当前时刻的预测值是不是都是结束符号，如果是，直接退出循环\n",
    "                if eos_token_ids is None:\n",
    "                    eos_token_ids = token_ids_i   # [N,1]\n",
    "                    is_eos = (eos_token_ids == self.eos_token_id).to(token_ids_i.dtype)   # 是eos的就是1，不是的就是0\n",
    "\n",
    "                eos_token_ids = eos_token_ids * is_eos + token_ids_i * (1 - is_eos)  # 合并数据\n",
    "                is_eos = (eos_token_ids == self.eos_token_id).to(token_ids_i.dtype)  # 是eos的就是1，不是的就是0\n",
    "                eos_number = torch.sum(is_eos).item()\n",
    "                if eos_number >= n:\n",
    "                    break\n",
    "\n",
    "                # 更新下一个时刻的输入 --> 将当前时刻的预测token id作为下一个时刻的输入\n",
    "                xi = self.embedding_layer(token_ids_i)[:, 0, :]\n",
    "            outputs = torch.concat(outputs, dim=1)  # [N,T2]\n",
    "            return outputs\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is in train mode\n",
      "torch.Size([2, 6, 100])\n"
     ]
    }
   ],
   "source": [
    "net2 = DecoderModule(vocab_size=100, embedding_dim=3, encoder_state_dim=net.output_dim)\n",
    "y = torch.randint(50, size=(2, 6))\n",
    "# net2.eval()\n",
    "r2 = net2(y, c)\n",
    "print(r2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderModule(\n",
      "  (embedding_layer): Embedding(100, 3)\n",
      "  (rnn_state_proj): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (rnn): RNN(3, 3, batch_first=True)\n",
      "  (proj): Linear(in_features=3, out_features=100, bias=True)\n",
      "  (rnn_cell): RNNCell(3, 3)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is in eval mode\n",
      "Serving 'decodermodel.onnx' at http://localhost:19610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9s/6rct71j56zx26pp1240rm_pw0000gn/T/ipykernel_28401/3720581094.py:79: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  eos_number = torch.sum(is_eos).item()\n",
      "/var/folders/9s/6rct71j56zx26pp1240rm_pw0000gn/T/ipykernel_28401/3720581094.py:80: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if eos_number >= n:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 19610)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import netron\n",
    "\n",
    "# 设置模型为评估模式\n",
    "net2.eval()\n",
    "\n",
    "# 创建示例输入\n",
    "# x: [batch_size, sequence_length]\n",
    "dummy_input_x = torch.randint(0, 50, size=(2, 4))  # 假设词汇表大小为50\n",
    "# encoder_state: [batch_size, encoder_state_dim]\n",
    "dummy_input_encoder_state = torch.randn(2, net2.hidden_size)  # 假设encoder_state_dim等于hidden_size\n",
    "\n",
    "# 导出模型为 ONNX 格式\n",
    "output_file = \"decodermodel.onnx\"\n",
    "torch.onnx.export(net2, \n",
    "                  (dummy_input_x, dummy_input_encoder_state),  # 传入两个dummy inputs\n",
    "                  output_file,\n",
    "                  export_params=True,        # 存储训练过的参数\n",
    "                  opset_version=10,         # ONNX 版本\n",
    "                  do_constant_folding=True, # 是否执行常量折叠优化\n",
    "                  input_names=['x', 'encoder_state'],    # 输入名称\n",
    "                  output_names=['output'],  # 输出名称\n",
    "                  dynamic_axes={'x': {0: 'batch_size'}, 'encoder_state': {0: 'batch_size'}, 'output': {0: 'batch_size'}}) # 批次大小动态\n",
    "\n",
    "# 使用 netron 查看 ONNX 模型\n",
    "netron.start(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "import netron\n",
    "\n",
    "# 设置模型为评估模式\n",
    "net2.eval()\n",
    "\n",
    "# 创建示例输入\n",
    "dummy_input = torch.randint(50, size=(2, 4))\n",
    "\n",
    "# 导出模型为 ONNX 格式\n",
    "output_file = \"decodermodel.onnx\"\n",
    "torch.onnx.export(net2, dummy_input, output_file,\n",
    "                  export_params=True,        # 存储训练过的参数\n",
    "                  opset_version=10,         # ONNX 版本\n",
    "                  do_constant_folding=True, # 是否执行常量折叠优化\n",
    "                  input_names=['input'],    # 输入名称\n",
    "                  output_names=['output'],  # 输出名称\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}} # 批次大小动态\n",
    "                  )\n",
    "\n",
    "# print(f\"ONNX model exported to {output_file}\")\n",
    "\n",
    "# 使用 netron 查看 ONNX 模型\n",
    "netron.start(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2SeqModel"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T02:12:15.735652Z",
     "start_time": "2025-01-14T02:12:15.725299Z"
    }
   },
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim,\n",
    "                 encoder_num_layers=1, encoder_bidirectional=True, encoder_hidden_size=None,\n",
    "                 decoder_num_layers=1, decoder_vocab_size=None, decoder_embedding_dim=None, decoder_hidden_size=None,\n",
    "                 eos_token_id=0,\n",
    "\n",
    "                 ):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "\n",
    "        self.encoder = EncoderModule(\n",
    "            vocab_size, embedding_dim, hidden_size=encoder_hidden_size,\n",
    "            num_layers=encoder_num_layers, bidirectional=encoder_bidirectional\n",
    "        )\n",
    "        self.decoder = DecoderModule(\n",
    "            decoder_vocab_size or vocab_size, decoder_embedding_dim or embedding_dim,\n",
    "            hidden_size=decoder_hidden_size,\n",
    "            encoder_state_dim=self.encoder.output_dim, num_layers=decoder_num_layers,\n",
    "            eos_token_id=eos_token_id,\n",
    "            # eos_token_id=6,  # 临时更改，为了预测退出逻辑\n",
    "            max_seq_length=200\n",
    "        )\n",
    "        self.eos_token_id = eos_token_id\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, encoder_input_ids, label_ids=None):\n",
    "        \"\"\"\n",
    "        前向过程： 前向预测 + loss\n",
    "        NOTE: loss仅在训练的时候计算\n",
    "        :param encoder_input_ids: [N,T1] token id tensor列表\n",
    "        :param label_ids: [N,T2] 训练时候给定的标签id列表，推理预测的时候为None\n",
    "        :return: [N,T2,vocab_size], loss\n",
    "        \"\"\"\n",
    "        # 1. 基于编码器提取特征\n",
    "        c = self.encoder(encoder_input_ids)\n",
    "        # 2. 解码器操作\n",
    "        if self.training:\n",
    "            # 获取解码器的信息：解码器的输入label_ids的偏移 + 编码器的状态信息\n",
    "            eos_ids = torch.zeros(size=(label_ids.shape[0], 1), dtype=label_ids.dtype)\n",
    "            torch.fill_(eos_ids, self.eos_token_id)\n",
    "            shift_decoder_input_ids = torch.concat([eos_ids, label_ids], dim=1)  # [N,T2+1]\n",
    "            shift_decoder_output_ids = torch.concat([label_ids, eos_ids], dim=1)  # [N,T2+1]\n",
    "            scores = self.decoder(shift_decoder_input_ids, c)  # [N,T2+1,vocab_size]\n",
    "            # 损失的计算\n",
    "            loss = self.loss_fn(torch.permute(scores, dims=[0, 2, 1]), shift_decoder_output_ids)\n",
    "            return scores, loss\n",
    "        else:\n",
    "            # 构建解码器第一个时刻的输入\n",
    "            eos_ids = torch.zeros(size=(encoder_input_ids.shape[0], 1), dtype=torch.long)\n",
    "            torch.fill_(eos_ids, self.eos_token_id)\n",
    "            token_ids = self.decoder(eos_ids, c)  # [N,T2+1,vocab_size]\n",
    "            return token_ids\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2SeqModel_1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T02:12:38.639843Z",
     "start_time": "2025-01-14T02:12:38.577994Z"
    }
   },
   "source": [
    "# 假定场景: 词典大小为26个字母 + 一个特殊值<EOS> + 一个特殊值<PAD>\n",
    "# 有一条样本，编码器的输入: a b c，解码器的最终输出: w x y z\n",
    "# 对数据做转换:\n",
    "# ** 编码器输入: a b c\n",
    "# ** 解码器输入: <EOS> w x y z\n",
    "# ** 解码器输出: w x y z <EOS>\n",
    "# 解码器理解成序列生成，生成序列的时候是不是要一个字符/token一个字符/token来生成，在生成当前token/字符的时候，和是之前的token有强烈的关联关系的\n",
    "# 词典映射关系: {<EOS>:0, a:1, b:2, c:3, ......, w:23, x:24, y:25, z:26, <PAD>:27}\n",
    "x_id = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 5]\n",
    "])\n",
    "label_ids = torch.tensor([\n",
    "    [23, 24, 25, 26],\n",
    "    [23, 24, 25, 26]\n",
    "])\n",
    "net = Seq2SeqModel(\n",
    "    vocab_size=28,\n",
    "    embedding_dim=4,\n",
    "    encoder_num_layers=1,\n",
    "    encoder_hidden_size=16,\n",
    "    decoder_hidden_size=16,\n",
    "    eos_token_id=0\n",
    ")\n",
    "_scores, _loss = net(x_id, label_ids)\n",
    "print(_scores.shape)\n",
    "print(_loss)\n",
    "\n",
    "net.eval()\n",
    "_predict_token_ids = net(x_id)\n",
    "print(_predict_token_ids)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 28])\n",
      "tensor(3.4099, grad_fn=<NllLoss2DBackward0>)\n",
      "tensor([[11,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1],\n",
      "        [11,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1]])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2SeqModel_2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T02:12:47.369263Z",
     "start_time": "2025-01-14T02:12:47.345383Z"
    }
   },
   "source": [
    "# 假定翻译场景（中译英）：编码器和解码器的词典大小不一样的\n",
    "# 有一条样本，编码器的输入: 小明 吃 苹果，解码器的最终输出：xiao  ming  eats  apples\n",
    "# 对数据做转换:\n",
    "# ** 编码器输入: 小明 吃 苹果\n",
    "# ** 解码器输入: <begin> xiao  ming  eats  apples\n",
    "# ** 解码器输出: xiao  ming  eats  apples <end>\n",
    "# 解码器理解成序列生成，生成序列的时候是不是要一个字符/token一个字符/token来生成，在生成当前token/字符的时候，和是之前的token有强烈的关联关系的\n",
    "net = Seq2SeqModel(\n",
    "    vocab_size=10000,  # 总共有10000个中文词语\n",
    "    embedding_dim=128,\n",
    "    encoder_hidden_size=64, encoder_num_layers=2, encoder_bidirectional=True,\n",
    "    decoder_num_layers=1,\n",
    "    decoder_vocab_size=3000,  # 总共有3000个英文词语\n",
    "    decoder_embedding_dim=64,\n",
    "    eos_token_id=0\n",
    ")\n",
    "print(net)\n",
    "x_id = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3]\n",
    "])\n",
    "label_ids = torch.tensor([\n",
    "    [23, 24, 25, 26],\n",
    "    [23, 24, 25, 26]\n",
    "])\n",
    "_scores, _loss = net(x_id, label_ids)\n",
    "print(_scores.shape)\n",
    "print(_loss)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqModel(\n",
      "  (encoder): EncoderModule(\n",
      "    (embedding_layer): Embedding(10000, 128)\n",
      "    (features): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (decoder): DecoderModule(\n",
      "    (embedding_layer): Embedding(3000, 64)\n",
      "    (rnn_state_proj): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (rnn): RNN(64, 64, batch_first=True)\n",
      "    (proj): Linear(in_features=64, out_features=3000, bias=True)\n",
      "    (rnn_cell): RNNCell(64, 64)\n",
      "  )\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n",
      "torch.Size([2, 5, 3000])\n",
      "tensor(8.0339, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lowercase2uppercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_data & dataloader"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T02:13:01.461195Z",
     "start_time": "2025-01-14T02:13:01.453128Z"
    }
   },
   "source": [
    "import string\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 生成一些示例数据\n",
    "def generate_data(num_samples=100):\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        word_length = random.randint(2, 10)\n",
    "        lowercase_word = ''.join(random.choices(string.ascii_lowercase, k=word_length))\n",
    "        uppercase_word = lowercase_word.upper()\n",
    "        data.append((lowercase_word, uppercase_word))\n",
    "    return data\n",
    "\n",
    "# 生成数据\n",
    "data = generate_data()\n",
    "\n",
    "# 构建词汇表\n",
    "vocab = ['<PAD>', '<EOS>'] + list(string.ascii_lowercase) + list(string.ascii_uppercase)\n",
    "vocab_size = len(vocab)\n",
    "char_to_id = {char: idx for idx, char in enumerate(vocab)}\n",
    "id_to_char = {idx: char for idx, char in enumerate(vocab)}\n",
    "\n",
    "# 将单词转换为ID序列\n",
    "def word_to_ids(word, char_to_id, max_length=10):\n",
    "    ids = [char_to_id[char] for char in word]\n",
    "    if len(ids) < max_length:\n",
    "        ids += [char_to_id['<PAD>']] * (max_length - len(ids))\n",
    "    return ids\n",
    "\n",
    "# 数据集类\n",
    "class CharTransformDataset(Dataset):\n",
    "    def __init__(self, data, char_to_id, max_length=10):\n",
    "        self.data = data\n",
    "        self.char_to_id = char_to_id\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lowercase_word, uppercase_word = self.data[idx]\n",
    "        x = word_to_ids(lowercase_word, self.char_to_id, self.max_length)\n",
    "        y = word_to_ids(uppercase_word, self.char_to_id, self.max_length)\n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    "# 创建数据集实例\n",
    "dataset = CharTransformDataset(data, char_to_id, max_length=10)\n",
    "\n",
    "# 创建DataLoader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 9, 16, 25,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [24, 16,  5,  9, 16, 11, 15,  0,  0,  0],\n",
       "         [14, 15, 17, 11,  6,  0,  0,  0,  0,  0],\n",
       "         [ 3, 16, 23, 26, 27, 18,  0,  0,  0,  0],\n",
       "         [21, 18,  6,  4, 20, 11,  4, 16,  0,  0],\n",
       "         [16,  6, 16, 22,  2, 21, 25,  8,  0,  0],\n",
       "         [ 8,  8, 21, 19, 23, 20, 23,  5,  5, 19],\n",
       "         [ 6, 19,  3,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 3,  4,  9, 10, 12, 18, 16,  2,  0,  0],\n",
       "         [ 5, 20,  4,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [10, 26, 19,  9,  0,  0,  0,  0,  0,  0],\n",
       "         [22, 21,  9, 11, 25,  0,  0,  0,  0,  0],\n",
       "         [10,  4,  6, 13,  0,  0,  0,  0,  0,  0],\n",
       "         [21, 23, 15, 17, 17, 24, 21, 15, 24,  0],\n",
       "         [ 4,  9, 15,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [18, 12, 18, 27,  0,  0,  0,  0,  0,  0],\n",
       "         [ 5, 24, 10, 13, 20, 24, 10,  0,  0,  0],\n",
       "         [ 2, 11,  2, 21, 13,  5,  0,  0,  0,  0],\n",
       "         [ 6, 16,  9,  7, 13,  0,  0,  0,  0,  0],\n",
       "         [ 9, 13, 11,  6, 13,  7,  5, 14, 11,  0],\n",
       "         [13, 27, 24, 22, 15, 26,  0,  0,  0,  0],\n",
       "         [12, 24,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [11,  8,  5, 20, 20, 17,  2,  0,  0,  0],\n",
       "         [ 6,  3,  3, 17,  0,  0,  0,  0,  0,  0],\n",
       "         [22,  4, 10, 24, 17,  3, 25, 26, 25, 11],\n",
       "         [25, 16, 25, 12,  0,  0,  0,  0,  0,  0],\n",
       "         [19, 17, 22,  6,  5,  8,  0,  0,  0,  0],\n",
       "         [20,  3, 10, 14, 15,  0,  0,  0,  0,  0],\n",
       "         [ 8, 24,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 3, 18, 22, 27,  4,  5, 13, 11, 25,  0],\n",
       "         [24, 16, 27,  3, 15,  0,  0,  0,  0,  0],\n",
       "         [20,  6, 17, 26, 14,  0,  0,  0,  0,  0]]),\n",
       " tensor([[35, 42, 51,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [50, 42, 31, 35, 42, 37, 41,  0,  0,  0],\n",
       "         [40, 41, 43, 37, 32,  0,  0,  0,  0,  0],\n",
       "         [29, 42, 49, 52, 53, 44,  0,  0,  0,  0],\n",
       "         [47, 44, 32, 30, 46, 37, 30, 42,  0,  0],\n",
       "         [42, 32, 42, 48, 28, 47, 51, 34,  0,  0],\n",
       "         [34, 34, 47, 45, 49, 46, 49, 31, 31, 45],\n",
       "         [32, 45, 29,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [29, 30, 35, 36, 38, 44, 42, 28,  0,  0],\n",
       "         [31, 46, 30,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [36, 52, 45, 35,  0,  0,  0,  0,  0,  0],\n",
       "         [48, 47, 35, 37, 51,  0,  0,  0,  0,  0],\n",
       "         [36, 30, 32, 39,  0,  0,  0,  0,  0,  0],\n",
       "         [47, 49, 41, 43, 43, 50, 47, 41, 50,  0],\n",
       "         [30, 35, 41,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [44, 38, 44, 53,  0,  0,  0,  0,  0,  0],\n",
       "         [31, 50, 36, 39, 46, 50, 36,  0,  0,  0],\n",
       "         [28, 37, 28, 47, 39, 31,  0,  0,  0,  0],\n",
       "         [32, 42, 35, 33, 39,  0,  0,  0,  0,  0],\n",
       "         [35, 39, 37, 32, 39, 33, 31, 40, 37,  0],\n",
       "         [39, 53, 50, 48, 41, 52,  0,  0,  0,  0],\n",
       "         [38, 50,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [37, 34, 31, 46, 46, 43, 28,  0,  0,  0],\n",
       "         [32, 29, 29, 43,  0,  0,  0,  0,  0,  0],\n",
       "         [48, 30, 36, 50, 43, 29, 51, 52, 51, 37],\n",
       "         [51, 42, 51, 38,  0,  0,  0,  0,  0,  0],\n",
       "         [45, 43, 48, 32, 31, 34,  0,  0,  0,  0],\n",
       "         [46, 29, 36, 40, 41,  0,  0,  0,  0,  0],\n",
       "         [34, 50,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [29, 44, 48, 53, 30, 31, 39, 37, 51,  0],\n",
       "         [50, 42, 53, 29, 41,  0,  0,  0,  0,  0],\n",
       "         [46, 32, 43, 52, 40,  0,  0,  0,  0,  0]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_iter = iter(dataloader)\n",
    "sample1 = next(dataset_iter)\n",
    "sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 10]), torch.Size([32, 10]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1[0].shape, sample1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([24, 16,  5,  9, 16, 11, 15,  0,  0,  0]),\n",
       " tensor([50, 42, 31, 35, 42, 37, 41,  0,  0,  0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i= 1\n",
    "sample1[0][i], sample1[1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# 模型参数\n",
    "embedding_dim = 32\n",
    "encoder_hidden_size = 64\n",
    "decoder_hidden_size = 64\n",
    "eos_token_id = char_to_id['<EOS>']\n",
    "\n",
    "# 初始化模型\n",
    "model = Seq2SeqModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    encoder_hidden_size=encoder_hidden_size,\n",
    "    decoder_hidden_size=decoder_hidden_size,\n",
    "    eos_token_id=eos_token_id\n",
    ")\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T02:13:12.348679Z",
     "start_time": "2025-01-14T02:13:12.335250Z"
    }
   },
   "source": [
    "# 模型参数\n",
    "embedding_dim = 32\n",
    "encoder_hidden_size = 64\n",
    "decoder_hidden_size = 64\n",
    "eos_token_id = char_to_id['<EOS>']\n",
    "\n",
    "# 初始化模型\n",
    "model = Seq2SeqModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    encoder_hidden_size=encoder_hidden_size,\n",
    "    decoder_hidden_size=decoder_hidden_size,\n",
    "    eos_token_id=eos_token_id\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T02:13:16.285661Z",
     "start_time": "2025-01-14T02:13:15.208801Z"
    }
   },
   "source": [
    "from torch import optim\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 加载模型\n",
    "model.load_state_dict(torch.load('seq2seq_model.pth'))\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, label_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        scores, loss = model(x_batch, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'seq2seq_model.pth')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\五行缺钱\\AppData\\Local\\Temp\\ipykernel_10968\\208309416.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('seq2seq_model.pth'))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'seq2seq_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# 加载模型\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseq2seq_model.pth\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# 训练循环\u001B[39;00m\n\u001B[0;32m     10\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m500\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:1065\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1062\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m   1063\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m-> 1065\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _open_file_like(f, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m   1066\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m   1067\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1068\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1069\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1070\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:468\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 468\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _open_file(name_or_buffer, mode)\n\u001B[0;32m    469\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    470\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:449\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 449\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mopen\u001B[39m(name, mode))\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'seq2seq_model.pth'"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vhnkxpyn -> Output: VHNKXPYN<EOS>\n",
      "Input: hoif -> Output: HOIF<EOS>\n",
      "Input: lqs -> Output: LQS<EOS>\n",
      "Input: kaz -> Output: KAZ<EOS>\n",
      "Input: dxyhqyrfah -> Output: DXYHQYRFAH<EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9s/6rct71j56zx26pp1240rm_pw0000gn/T/ipykernel_50074/1190607101.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('seq2seq_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "# 加载模型\n",
    "model.load_state_dict(torch.load('seq2seq_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 测试函数\n",
    "def test_model(model, input_word, char_to_id, id_to_char, max_length=10):\n",
    "    with torch.no_grad():\n",
    "        input_ids = word_to_ids(input_word, char_to_id, max_length)\n",
    "        input_tensor = torch.tensor([input_ids])\n",
    "        output_ids = model(input_tensor)\n",
    "        output_word = ''.join([id_to_char[id] for id in output_ids[0].tolist() if id != char_to_id['<PAD>']])\n",
    "        return output_word\n",
    "\n",
    "# 测试几个例子\n",
    "# test_words = ['hello', 'world', 'pytorch']\n",
    "test_words = data[:5]\n",
    "test_words = [lowercase_word[0] for lowercase_word in test_words]\n",
    "for word in test_words:\n",
    "    print(f\"Input: {word} -> Output: {test_model(model, word, char_to_id, id_to_char)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
