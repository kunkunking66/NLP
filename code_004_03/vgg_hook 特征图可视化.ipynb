{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-04T01:56:36.935492Z",
     "start_time": "2024-11-04T01:52:26.211994Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from PIL import Image as PILImage\n",
    "import os\n",
    "\n",
    "import torchvision.models\n",
    "from torchvision.models.vgg import VGG16_Weights\n",
    "\n",
    "# 加载预训练的VGG16模型，并使用默认权重。vgg.eval()将模型设置为评估模式，这意味着模型在推理时不会进行梯度更新\n",
    "vgg = torchvision.models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "vgg.eval()  # 设置为评估模式\n",
    "\n",
    "# # 加载预训练的 VGG 模型\n",
    "# vgg = torchvision.models.vgg16(pretrained=True)\n",
    "# vgg.eval()  # 设置为评估模式\n",
    "\n",
    "# 初始化一个字典来存储每层的输出\n",
    "vgg_hooks = {}\n",
    "\n",
    "# 作用：\n",
    "# 当你的模型进行前向传播时，它会捕获所有卷积层的输出，并将这些输出存储在hooks_dict字典中，其中字典的键是层的名字，值是包含该层所有输出的列表\n",
    "# 注册钩子函数到每一层\n",
    "def register_hooks(model, hooks_dict):  # 放入模型和字典\n",
    "    def hook(module, input, output):  # 放入当前层的模块 输入和输出\n",
    "        # 使用模块的名字作为键\n",
    "        module_name = str(module)\n",
    "        if module_name not in hooks_dict:  # 将当前层的输出output添加到hooks_dict字典中对应的列表里\n",
    "            hooks_dict[module_name] = []  # 如果字典中还没有这个键，则会创建一个新的空列表\n",
    "        hooks_dict[module_name].append(output)\n",
    "    \n",
    "    # 注册钩子到所有的卷积层\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            module.register_forward_hook(hook)\n",
    "\n",
    "# 注册钩子\n",
    "register_hooks(vgg.features, vgg_hooks)\n",
    "\n",
    "\n",
    "# 图片预处理\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # 使用ImageNet的均值和标准差\n",
    "])\n",
    "\n",
    "# 加载图片\n",
    "img = Image.open(\"lena.png\").convert(\"RGB\")\n",
    "img_tensor = img_transform(img).unsqueeze(0)  # 添加批次维度\n",
    "\n",
    "# 获取模型的预测结果\n",
    "scores = vgg(img_tensor)\n",
    "proba = torch.softmax(scores, dim=1)\n",
    "top5 = torch.topk(proba, k=5, dim=1)\n",
    "\n",
    "# 打印预测结果\n",
    "print(\"Image Name:\", \"lena.png\")\n",
    "print(\"Top 5 Predictions:\", top5)\n",
    "\n",
    "# 可视化中间层的输出\n",
    "output_dir = \"./vgg_feature_maps\"  # 定义输出目录\n",
    "os.makedirs(output_dir, exist_ok=True)  # 创建输出目录\n",
    "\n",
    "# 收集所有channel的feature maps\n",
    "all_features = []\n",
    "print (f\" len vgg_hooks: {len(vgg_hooks)}\")\n",
    "for module_name, features_list in vgg_hooks.items():\n",
    "    print (\"module_name: \", module_name)\n",
    "    # print (\"features_list: \", features_list)\n",
    "    # break\n",
    "    for features in features_list:\n",
    "        n, c, h, w = features.shape\n",
    "        print (f\"n, c, h, w: {n, c, h, w}\")\n",
    "        channel_images = []\n",
    "        \n",
    "        for i in range(c):  # 遍历每个channel\n",
    "            feature_map = features[0, i].cpu().detach()  # 获取单个channel的feature map\n",
    "            feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())  # 归一化\n",
    "            feature_map = (feature_map * 255).byte()  # 转换为0-255的灰度值\n",
    "            feature_map_pil = PILImage.fromarray(feature_map.numpy()).convert('L')\n",
    "            \n",
    "            # 保存单个channel的图片\n",
    "            feature_map_pil.save(os.path.join(output_dir, f\"layer_{module_name.replace('.', '_')}_channel_{i}.png\"))\n",
    "            \n",
    "            # 将图片添加到列表中用于后续拼接\n",
    "            channel_images.append(feature_map_pil)\n",
    "        \n",
    "        # 拼接所有channel的图片\n",
    "        combined_image = PILImage.new('RGB', (w * c, h))  # 水平拼接\n",
    "        for i, img in enumerate(channel_images):\n",
    "            combined_image.paste(img.convert('RGB'), (w * i, 0))\n",
    "        \n",
    "        # 保存拼接后的图片\n",
    "        all_features.append(combined_image)\n",
    "        combined_image.save(os.path.join(output_dir, f\"layer_{module_name.replace('.', '_')}_combined.png\"))\n",
    "\n",
    "# 如果有多个层，可以进一步将它们拼接起来\n",
    "if len(all_features) > 1:\n",
    "    final_combined = PILImage.new('RGB', (all_features[0].width, sum([img.height for img in all_features])))  # 垂直拼接\n",
    "    y_offset = 0\n",
    "    for img in all_features:\n",
    "        final_combined.paste(img, (0, y_offset))\n",
    "        y_offset += img.height\n",
    "    final_combined.save(os.path.join(output_dir, \"final_combined.png\"))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\五行缺钱/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [03:53<00:00, 2.37MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Name: lena.png\n",
      "Top 5 Predictions: torch.return_types.topk(\n",
      "values=tensor([[0.1427, 0.0897, 0.0712, 0.0469, 0.0379]], grad_fn=<TopkBackward0>),\n",
      "indices=tensor([[552, 452, 808, 515, 903]]))\n",
      " len vgg_hooks: 8\n",
      "module_name:  Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "n, c, h, w: (1, 64, 224, 224)\n",
      "module_name:  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "n, c, h, w: (1, 64, 224, 224)\n",
      "module_name:  Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "n, c, h, w: (1, 128, 112, 112)\n",
      "module_name:  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "n, c, h, w: (1, 128, 112, 112)\n",
      "module_name:  Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "n, c, h, w: (1, 256, 56, 56)\n",
      "module_name:  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "n, c, h, w: (1, 256, 56, 56)\n",
      "n, c, h, w: (1, 256, 56, 56)\n",
      "module_name:  Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "n, c, h, w: (1, 512, 28, 28)\n",
      "module_name:  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "n, c, h, w: (1, 512, 28, 28)\n",
      "n, c, h, w: (1, 512, 28, 28)\n",
      "n, c, h, w: (1, 512, 14, 14)\n",
      "n, c, h, w: (1, 512, 14, 14)\n",
      "n, c, h, w: (1, 512, 14, 14)\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
