{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T06:17:43.490759Z",
     "start_time": "2024-10-29T06:17:43.473413Z"
    }
   },
   "source": [
    "import torch\n",
    "# 导入PyTorch库的基本形式，它允许你访问PyTorch库中的所有功能，包括张量操作、自动微分、优化器、模型保存和加载等\n",
    "import torch.nn as nn\n",
    "# 更方便地访问构建神经网络所需的类和函数，例如层（如 nn.Linear、nn.Conv2d）、激活函数（如 nn.ReLU）、损失函数（如 nn.CrossEntropyLoss）等\n",
    "import torch.nn.functional as F\n",
    "# 它提供了一系列的函数，这些函数可以用于构建神经网络的层和损失函数\n",
    "from torchinfo import summary\n",
    "# 用于打印模型的详细摘要。这个摘要包括每一层的输出形状、参数数量、总参数数量以及模型的总计算量"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchinfo'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# 它提供了一系列的函数，这些函数可以用于构建神经网络的层和损失函数\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchinfo\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m summary\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torchinfo'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleCNNWithBatchNorm"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T06:18:11.391784Z",
     "start_time": "2024-10-29T06:18:11.383663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNNWithBatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNNWithBatchNorm, self).__init__()\n",
    "        # 卷积层1: 输入通道1，输出通道32，卷积核大小3x3\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # 批量归一化层1\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        # 卷积层2: 输入通道32，输出通道64，卷积核大小3x3\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # 批量归一化层2\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # 池化层: 最大池化\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 全连接层\n",
    "        # 初始化第一个全连接层。这里的输入特征数量是64 * 7 * 7，这是基于假设输入图片大小为28x28，并且经过两次2x2的最大池化后，特征图大小变为7x7。这个全连接层将这些特征连接到128个节点\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # 假设输入图片大小为28x28\n",
    "        # 初始化第二个全连接层，它将128个节点连接到10个输出节点，对应于10个类别\n",
    "        self.fc2 = nn.Linear(128, 10)  # 假设有10个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 通过卷积层1，批量归一化层1，使用ReLU激活函数，然后进行最大池化\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # 通过卷积层2，批量归一化层2，使用ReLU激活函数，然后进行最大池化\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        # 展平特征图\n",
    "        x = x.view(-1, 64 * 7 * 7)  # 将多维的特征图x展平成一个一维向量。这里假设经过两次池化后，特征图的大小为7x7，并且有64个通道，因此展平后的向量长度为64 * 7 * 7\n",
    "        # 通过全连接层1\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # 通过丢弃层（Dropout）\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        # 通过全连接层2输出最终结果\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T06:18:28.810326Z",
     "start_time": "2024-10-29T06:18:28.763873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 实例化模型\n",
    "model = SimpleCNNWithBatchNorm()\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNNWithBatchNorm(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## onnx"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T06:18:37.283427Z",
     "start_time": "2024-10-29T06:18:36.803780Z"
    }
   },
   "source": [
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 创建示例输入\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "# 导出模型为 ONNX 格式\n",
    "output_file = \"SimpleCNNWithBatchNorm.onnx\"\n",
    "torch.onnx.export(model, dummy_input, output_file,\n",
    "                  export_params=True,        # 存储训练过的参数\n",
    "                  opset_version=10,         # ONNX 版本\n",
    "                  do_constant_folding=True, # 是否执行常量折叠优化\n",
    "                  input_names=['input'],    # 输入名称\n",
    "                  output_names=['output'],  # 输出名称\n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}} # 批次大小动态\n",
    "                  )\n",
    "\n",
    "print(f\"ONNX model exported to {output_file}\")"
   ],
   "outputs": [
    {
     "ename": "OnnxExporterError",
     "evalue": "Module onnx is not installed!",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\onnx\\_internal\\onnx_proto_utils.py:220\u001B[0m, in \u001B[0;36m_add_onnxscript_fn\u001B[1;34m(model_bytes, custom_opsets)\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 220\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'onnx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mOnnxExporterError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# 导出模型为 ONNX 格式\u001B[39;00m\n\u001B[0;32m      8\u001B[0m output_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSimpleCNNWithBatchNorm.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 9\u001B[0m torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mexport(model, dummy_input, output_file,\n\u001B[0;32m     10\u001B[0m                   export_params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,        \u001B[38;5;66;03m# 存储训练过的参数\u001B[39;00m\n\u001B[0;32m     11\u001B[0m                   opset_version\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m,         \u001B[38;5;66;03m# ONNX 版本\u001B[39;00m\n\u001B[0;32m     12\u001B[0m                   do_constant_folding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;66;03m# 是否执行常量折叠优化\u001B[39;00m\n\u001B[0;32m     13\u001B[0m                   input_names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m],    \u001B[38;5;66;03m# 输入名称\u001B[39;00m\n\u001B[0;32m     14\u001B[0m                   output_names\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput\u001B[39m\u001B[38;5;124m'\u001B[39m],  \u001B[38;5;66;03m# 输出名称\u001B[39;00m\n\u001B[0;32m     15\u001B[0m                   dynamic_axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;241m0\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m}, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;241m0\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m}} \u001B[38;5;66;03m# 批次大小动态\u001B[39;00m\n\u001B[0;32m     16\u001B[0m                   )\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mONNX model exported to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moutput_file\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\onnx\\utils.py:551\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining, dynamo)\u001B[0m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m f \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    547\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    548\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExport destination must be specified for torchscript-onnx export.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    549\u001B[0m     )\n\u001B[1;32m--> 551\u001B[0m _export(\n\u001B[0;32m    552\u001B[0m     model,\n\u001B[0;32m    553\u001B[0m     args,\n\u001B[0;32m    554\u001B[0m     f,\n\u001B[0;32m    555\u001B[0m     export_params,\n\u001B[0;32m    556\u001B[0m     verbose,\n\u001B[0;32m    557\u001B[0m     training,\n\u001B[0;32m    558\u001B[0m     input_names,\n\u001B[0;32m    559\u001B[0m     output_names,\n\u001B[0;32m    560\u001B[0m     operator_export_type\u001B[38;5;241m=\u001B[39moperator_export_type,\n\u001B[0;32m    561\u001B[0m     opset_version\u001B[38;5;241m=\u001B[39mopset_version,\n\u001B[0;32m    562\u001B[0m     do_constant_folding\u001B[38;5;241m=\u001B[39mdo_constant_folding,\n\u001B[0;32m    563\u001B[0m     dynamic_axes\u001B[38;5;241m=\u001B[39mdynamic_axes,\n\u001B[0;32m    564\u001B[0m     keep_initializers_as_inputs\u001B[38;5;241m=\u001B[39mkeep_initializers_as_inputs,\n\u001B[0;32m    565\u001B[0m     custom_opsets\u001B[38;5;241m=\u001B[39mcustom_opsets,\n\u001B[0;32m    566\u001B[0m     export_modules_as_functions\u001B[38;5;241m=\u001B[39mexport_modules_as_functions,\n\u001B[0;32m    567\u001B[0m     autograd_inlining\u001B[38;5;241m=\u001B[39mautograd_inlining,\n\u001B[0;32m    568\u001B[0m )\n\u001B[0;32m    570\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\onnx\\utils.py:1722\u001B[0m, in \u001B[0;36m_export\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001B[0m\n\u001B[0;32m   1703\u001B[0m     (\n\u001B[0;32m   1704\u001B[0m         proto,\n\u001B[0;32m   1705\u001B[0m         export_map,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1719\u001B[0m         node_attr_to_name,\n\u001B[0;32m   1720\u001B[0m     )\n\u001B[0;32m   1721\u001B[0m \u001B[38;5;66;03m# insert function_proto into model_proto.\u001B[39;00m\n\u001B[1;32m-> 1722\u001B[0m proto \u001B[38;5;241m=\u001B[39m onnx_proto_utils\u001B[38;5;241m.\u001B[39m_add_onnxscript_fn(\n\u001B[0;32m   1723\u001B[0m     proto,\n\u001B[0;32m   1724\u001B[0m     custom_opsets,\n\u001B[0;32m   1725\u001B[0m )\n\u001B[0;32m   1726\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[0;32m   1727\u001B[0m     torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExported graph: \u001B[39m\u001B[38;5;124m\"\u001B[39m, graph)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\onnx\\_internal\\onnx_proto_utils.py:222\u001B[0m, in \u001B[0;36m_add_onnxscript_fn\u001B[1;34m(model_bytes, custom_opsets)\u001B[0m\n\u001B[0;32m    220\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01monnx\u001B[39;00m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 222\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOnnxExporterError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModule onnx is not installed!\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;66;03m# For > 2GB model, onnx.load_fromstring would fail. However, because\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;66;03m# in _export_onnx, the tensors should be saved separately if the proto\u001B[39;00m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;66;03m# size > 2GB, and if it for some reason did not, the model would fail on\u001B[39;00m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;66;03m# serialization anyway in terms of the protobuf limitation. So we don't\u001B[39;00m\n\u001B[0;32m    228\u001B[0m \u001B[38;5;66;03m# need to worry about > 2GB model getting here.\u001B[39;00m\n\u001B[0;32m    229\u001B[0m model_proto \u001B[38;5;241m=\u001B[39m onnx\u001B[38;5;241m.\u001B[39mload_model_from_string(model_bytes)  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
      "\u001B[1;31mOnnxExporterError\u001B[0m: Module onnx is not installed!"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'SimpleCNNWithBatchNorm.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "\n",
    "# 使用 netron 查看 ONNX 模型\n",
    "netron.start(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
