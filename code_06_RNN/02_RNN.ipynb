{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T05:44:03.457923Z",
     "start_time": "2024-11-27T05:44:00.043343Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN -> RNNCell"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T06:01:50.976326Z",
     "start_time": "2024-11-27T06:01:50.964734Z"
    }
   },
   "source": [
    "# embedding 的作用是将离散的词汇映射到连续的向量空间\n",
    "# 创建了一个嵌入层，其中num_embeddings=100表示词汇表大小为100，embedding_dim=5表示每个词汇的嵌入向量维度为5\n",
    "embed_layer = nn.Embedding(num_embeddings=100, embedding_dim=5)\n",
    "fc_layer = nn.Linear(5, 6, bias=False)\n",
    "# 原始输入 --> 原始输入一般输入的是token id列表，[N,T]表示N个文本，每个文本T个token\n",
    "x = torch.randint(100, size=(4, 16))\n",
    "# embedding将x的16个特征的每一个特征映射到5维\n",
    "print(x.shape)\n",
    "x = embed_layer(x)  # [N,T] -> [N,T,E]\n",
    "print(x.shape)\n",
    "# 在PyTorch中，nn.Linear层会自动对最后一个维度进行矩阵乘法，所以这里的操作实际上是对每个序列的每个token的5维向量进行线性变换，得到6维向量\n",
    "x2 = fc_layer(x)  # dot([N,T,E], [E,E2]) --> [N,T,E2]\n",
    "print(x2.shape)\n",
    "print(x2[0][:3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n",
      "torch.Size([4, 16, 5])\n",
      "torch.Size([4, 16, 6])\n",
      "tensor([[-1.1337,  0.3365,  0.3753,  1.1819,  1.0518,  0.1465],\n",
      "        [ 0.5635,  0.1306,  0.5549, -0.4253, -0.2323,  0.0867],\n",
      "        [-0.8078, -0.6334, -0.0954, -0.5659,  0.3392, -0.0654]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T06:01:53.645692Z",
     "start_time": "2024-11-27T06:01:53.634793Z"
    }
   },
   "source": [
    "fc_layer.weight.T.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5323,  0.0053, -0.7381, -0.7990, -0.3872, -0.2328],\n",
      "        [ 0.4266, -0.1517, -0.7670,  0.2292,  0.2249,  1.0018],\n",
      "        [ 0.4354,  0.2249,  0.4269,  0.4689, -0.1023, -0.3638]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "====================\n",
      "tensor([ 0.5323,  0.0053, -0.7381, -0.7990, -0.3872, -0.2328],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.4266, -0.1517, -0.7670,  0.2292,  0.2249,  1.0018],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.4354,  0.2249,  0.4269,  0.4689, -0.1023, -0.3638],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N, T, E = x.shape   # [4, 16, 5]\n",
    "for i in range(N):\n",
    "    # matmul进行矩阵乘法\n",
    "    xi = torch.matmul(x[i], fc_layer.weight.T)\n",
    "    print(xi[:3])  # xi  [16,6]   # 第i个样本的前3个时刻\n",
    "    break\n",
    "\n",
    "print (\"=\"*20)\n",
    "for j in range(T):\n",
    "    xj = torch.matmul(x[:, j, :], fc_layer.weight.T)\n",
    "    print(xj[0])  # 第0个样本的第j个时刻的值\n",
    "    if j >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试1\n",
    "\n",
    "无记忆信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n",
      "torch.Size([4, 16, 5])\n"
     ]
    }
   ],
   "source": [
    "embed_layer = nn.Embedding(num_embeddings=100, embedding_dim=5)\n",
    "w1 = nn.Parameter(torch.randn(5, 6))\n",
    "# 原始输入 --> 原始输入一般输入的是token id列表，[N,T]表示N个文本，每个文本T个token\n",
    "x = torch.randint(100, size=(4, 16))\n",
    "print(x.shape)\n",
    "x = embed_layer(x)  # [N,T] -> [N,T,E]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.4380,  0.2844,  3.5782, -0.7446,  0.0423, -1.0942],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([-0.6224, -5.1465, -7.7115,  0.5931, -0.6324, -2.6013],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([4, 1, 6])\n",
      "torch.Size([4, 16, 6])\n",
      "torch.Size([4, 16, 6])\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N, T, E = x.shape\n",
    "outputs = []\n",
    "for j in range(T):\n",
    "    xj = torch.matmul(x[:, j, :], w1)  # 所有样本第j个时刻的特征值\n",
    "    if j < 2:\n",
    "        print(xj[0])  # 第0个样本的第j个时刻的值\n",
    "    # print (xj.shape)\n",
    "    xj = torch.unsqueeze(xj, dim=1)\n",
    "    # print (xj.shape)\n",
    "    outputs.append(xj)\n",
    "print(outputs[0].shape)\n",
    "outputs = torch.concat(outputs, dim=1)\n",
    "print(outputs.shape)\n",
    "\n",
    "outputs2 = torch.matmul(x, w1)  # 对应的Linear的计算\n",
    "print(outputs2.shape)\n",
    "\n",
    "print(torch.mean((outputs2 - outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试2\n",
    "\n",
    "有记忆信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16])\n",
      "torch.Size([4, 16, 5])\n"
     ]
    }
   ],
   "source": [
    "embed_layer = nn.Embedding(num_embeddings=100, embedding_dim=5)\n",
    "w1 = nn.Parameter(torch.randn(5, 6))\n",
    "w2 = nn.Parameter(torch.randn(6, 6))\n",
    "# 原始输入 --> 原始输入一般输入的是token id列表，[N,T]表示N个文本，每个文本T个token\n",
    "x = torch.randint(100, size=(4, 16))\n",
    "print(x.shape)\n",
    "x = embed_layer(x)  # [N,T] -> [N,T,E]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5002,  0.8570,  0.9604, -2.7841, -0.2044, -0.7272],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 2.6479,  1.7846, -3.7785,  7.6299,  2.6714, -2.5300],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([4, 16, 6])\n"
     ]
    }
   ],
   "source": [
    "N, T, E = x.shape\n",
    "states = torch.zeros(size=(N, w1.shape[1]))  # 记忆的状态信息\n",
    "outputs = []\n",
    "for j in range(T):\n",
    "    # 分步进行矩阵运算\n",
    "    xj = torch.matmul(x[:, j, :], w1)  # 所有样本第j个时刻的当前特征值 [N,6]\n",
    "    pre_states = torch.matmul(states, w2)  # 上一个时刻的，每个样本的记忆信息 [N,6]\n",
    "    xj = xj + pre_states  # 将当前的特征和之前的序列特征合并到一起\n",
    "    states = xj  # 当前的输入作为当前时刻的记忆信息\n",
    "\n",
    "    if j < 2:\n",
    "        print(xj[0])  # 第0个样本的第j个时刻的值\n",
    "    xj = torch.unsqueeze(xj, dim=1)\n",
    "    outputs.append(xj)\n",
    "outputs1 = torch.concat(outputs, dim=1)\n",
    "print(outputs1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.5002,  0.8570,  0.9604, -2.7841, -0.2044, -0.7272],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 2.6479,  1.7846, -3.7785,  7.6299,  2.6714, -2.5300],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "torch.Size([4, 16, 6])\n",
      "tensor(-2.7506e-05, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "states = torch.zeros(size=(N, w1.shape[1]))  # 记忆的状态信息\n",
    "outputs = []\n",
    "w3 = torch.concat([w1, w2], dim=0)  # [5+6, 6]\n",
    "for j in range(T):\n",
    "    # 参数concat，一步矩阵运算\n",
    "    xj = torch.concat([x[:, j, :], states], dim=1)  # [N,5+6]\n",
    "    xj = torch.matmul(xj, w3)  # 当前时刻的特征信息\n",
    "    states = xj  # 当前的输入作为当前时刻的记忆信息\n",
    "\n",
    "    if j < 2:\n",
    "        print(xj[0])  # 第0个样本的第j个时刻的值\n",
    "    xj = torch.unsqueeze(xj, dim=1)   # [N,6] -> [N,1,6]\n",
    "    outputs.append(xj)\n",
    "outputs2 = torch.concat(outputs, dim=1)\n",
    "print(outputs2.shape)\n",
    "print(torch.mean(outputs1 - outputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN参数理解"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T07:07:19.270576Z",
     "start_time": "2024-11-27T07:07:19.236919Z"
    }
   },
   "source": [
    "rnn = nn.RNN(\n",
    "    input_size=5,\n",
    "    hidden_size=6,\n",
    "    num_layers=2,  # 有多少层rnn\n",
    "    nonlinearity='tanh',  # 激活函数 tanh、relu，默认不支持的\n",
    "    batch_first=True,  # 输入数据的维度格式: true->[N,T,E] 或者 false->[T,N,E]\n",
    "    bidirectional=False  # 是否是双向RNN\n",
    ")\n",
    "print(len(list(rnn.parameters())))\n",
    "for name, param in list(rnn.named_parameters()):\n",
    "    print(f\"{name} --- {param.shape}\")\n",
    "\n",
    "x = torch.randn(4, 16, 5)\n",
    "# 返回的是一个Tuple，\n",
    "# 第一个元素是每个时刻的输出信息[N,T,hidden_size*(2 if bidirectional else 1)]\n",
    "# 第二个元素是最后一个时刻的状态信息\n",
    "outputs, hn = rnn(x)\n",
    "print(outputs.shape)  # [N,T,hidden_size*(2 if bidirectional else 1)]\n",
    "print(hn.shape)  # [(2 if bidirectional else 1) * num_layers, N, hidden_size]\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "weight_ih_l0 --- torch.Size([6, 5])\n",
      "weight_hh_l0 --- torch.Size([6, 6])\n",
      "bias_ih_l0 --- torch.Size([6])\n",
      "bias_hh_l0 --- torch.Size([6])\n",
      "weight_ih_l1 --- torch.Size([6, 6])\n",
      "weight_hh_l1 --- torch.Size([6, 6])\n",
      "bias_ih_l1 --- torch.Size([6])\n",
      "bias_hh_l1 --- torch.Size([6])\n",
      "torch.Size([4, 16, 6])\n",
      "torch.Size([2, 4, 6])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6009,  0.3361,  0.4664,  0.6237,  0.1764,  0.5827],\n",
       "        [-0.1840,  0.3164,  0.0512, -0.2778,  0.7838, -0.2781],\n",
       "        [-0.5195,  0.4852, -0.3609,  0.1783,  0.5618, -0.1561],\n",
       "        [-0.3937,  0.0829,  0.1113,  0.3195,  0.6565,  0.0419]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6009,  0.3361,  0.4664,  0.6237,  0.1764,  0.5827],\n",
       "        [-0.1840,  0.3164,  0.0512, -0.2778,  0.7838, -0.2781],\n",
       "        [-0.5195,  0.4852, -0.3609,  0.1783,  0.5618, -0.1561],\n",
       "        [-0.3937,  0.0829,  0.1113,  0.3195,  0.6565,  0.0419]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn[-1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层RNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 16, 5]) torch.Size([4, 16, 6]) torch.Size([4, 16, 6])\n",
      "torch.Size([4, 16, 6])\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(5, 6, num_layers=2, batch_first=True)   # 2层RNN\n",
    "\n",
    "rnn1 = nn.RNN(5, 6, num_layers=1, batch_first=True)  # 1层RNN\n",
    "rnn.weight_ih_l0 = rnn1.weight_ih_l0\n",
    "rnn.weight_hh_l0 = rnn1.weight_hh_l0\n",
    "rnn.bias_ih_l0 = rnn1.bias_ih_l0\n",
    "rnn.bias_hh_l0 = rnn1.bias_hh_l0\n",
    "\n",
    "rnn2 = nn.RNN(6, 6, num_layers=1, batch_first=True)  # 1层RNN\n",
    "rnn.weight_ih_l1 = rnn2.weight_ih_l0\n",
    "rnn.weight_hh_l1 = rnn2.weight_hh_l0\n",
    "rnn.bias_ih_l1 = rnn2.bias_ih_l0\n",
    "rnn.bias_hh_l1 = rnn2.bias_hh_l0\n",
    "\n",
    "# 手动多层RNN\n",
    "x = torch.randn(4, 16, 5)\n",
    "z1, z1_hn = rnn1(x)  # [4,16,5] -> [4,16,6]\n",
    "z2, z2_hn = rnn2(z1)  # [4,16,6] -> [4,16,6]\n",
    "print(x.shape, z1.shape, z2.shape)\n",
    "\n",
    "# 一次性多层RNN\n",
    "z, z_hn = rnn(x)\n",
    "# 第一个元素是每个时刻的输出信息[N,T,hidden_size*(2 if bidirectional else 1)]\n",
    "# 第二个元素是最后一个时刻的状态信息（所有层）\n",
    "print(z.shape)\n",
    "print(torch.mean(z - z2))\n",
    "print(torch.mean(z_hn[0] - z1_hn[0]))\n",
    "print(torch.mean(z_hn[1] - z2_hn[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN与手动RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.2392, -0.3527, -0.1397, -0.0224,  0.8324,  0.4148],\n",
      "         [-0.5996, -0.6327, -0.4335,  0.8206, -0.6344, -0.9057],\n",
      "         [ 0.3178, -0.4827, -0.8100,  0.7526, -0.4380,  0.3839],\n",
      "         [ 0.2191,  0.0669, -0.5125, -0.0014,  0.6231, -0.3698]],\n",
      "\n",
      "        [[-0.0683, -0.6586,  0.2314,  0.1382, -0.0557, -0.6852],\n",
      "         [-0.0458,  0.1359, -0.9235,  0.4663,  0.1652,  0.7605],\n",
      "         [-0.2023, -0.2630,  0.3109,  0.4793,  0.8942,  0.1332],\n",
      "         [-0.4330,  0.3109, -0.6638, -0.4971,  0.8337,  0.0388]]],\n",
      "       grad_fn=<TransposeBackward1>), tensor([[[ 0.2191,  0.0669, -0.5125, -0.0014,  0.6231, -0.3698],\n",
      "         [-0.4330,  0.3109, -0.6638, -0.4971,  0.8337,  0.0388]]],\n",
      "       grad_fn=<StackBackward0>))\n",
      "weight_ih_l0 --- torch.Size([6, 5])\n",
      "weight_hh_l0 --- torch.Size([6, 6])\n",
      "bias_ih_l0 --- torch.Size([6])\n",
      "bias_hh_l0 --- torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "rnn1 = nn.RNN(5, 6, num_layers=1, batch_first=True, bidirectional=False)\n",
    "\n",
    "x = torch.randn(2, 4, 5)\n",
    "n, t, e = x.shape\n",
    "z1 = rnn1(x)  # [2,4,5] -> [2,4,6]\n",
    "print(z1)\n",
    "\n",
    "# NOTE: 从rnn1中提取参数，然后基于rnn的结构，自己基于matmul进行矩阵运算\n",
    "# print(list(rnn1.named_parameters()))\n",
    "for name, param in list(rnn1.named_parameters()):\n",
    "    print(f\"{name} --- {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 6])\n",
      "torch.Size([2, 4, 6])\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "states = torch.zeros((1, n, 6))\n",
    "outputs = []\n",
    "# 针对每个时刻进行遍历\n",
    "for j in range(t):\n",
    "    # 针对当前时刻的输入\n",
    "    z_t = torch.matmul(x[:, j, :], rnn1.weight_ih_l0.T) + rnn1.bias_ih_l0\n",
    "    # 针对上一个时刻的状态信息的转换\n",
    "    h_pt = torch.matmul(states[0], rnn1.weight_hh_l0.T) + rnn1.bias_hh_l0\n",
    "    # 将当前时刻的输入提取特征和上一个时刻的特征合并\n",
    "    \n",
    "    zh = z_t + h_pt\n",
    "    # 做一个激活函数\n",
    "    zh = torch.tanh(zh)\n",
    "    # 当前时刻的最终输出以及状态信息的保存\n",
    "    outputs.append(torch.unsqueeze(zh, dim=1))  # 输出的特征信息\n",
    "    states[0] = zh  # 当前时刻的状态信息\n",
    "print(states.shape)\n",
    "outputs = torch.concat(outputs, dim=1)\n",
    "print(outputs.shape)\n",
    "print(torch.mean(torch.abs(outputs - z1[0])))\n",
    "print(torch.mean(torch.abs(states - z1[1])))\n",
    "\n",
    "output_proj = nn.Linear(6, 3)\n",
    "outputs = output_proj(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6]), torch.Size([2, 6]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_t.shape, h_pt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN ~ bidirectional=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 12])\n",
      "torch.Size([2, 3, 6])\n",
      "dict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0', 'weight_ih_l0_reverse', 'weight_hh_l0_reverse', 'bias_ih_l0_reverse', 'bias_hh_l0_reverse'])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(5, 6, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "x = torch.randn(3, 4, 5)\n",
    "ho, hn = rnn(x)  # ho: 每个时刻的输出， hn：每个rnn的最后一个时刻的状态\n",
    "print(ho.shape)\n",
    "print(hn.shape)\n",
    "print(dict(rnn.named_parameters()).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 6]) torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "rnn1 = nn.RNN(5, 6, num_layers=1, batch_first=True, bidirectional=False)  # 正向rnn\n",
    "rnn1.weight_ih_l0 = rnn.weight_ih_l0\n",
    "rnn1.weight_hh_l0 = rnn.weight_hh_l0\n",
    "rnn1.bias_ih_l0 = rnn.bias_ih_l0\n",
    "rnn1.bias_hh_l0 = rnn.bias_hh_l0\n",
    "ho1, hn1 = rnn1(x)\n",
    "print (ho1.shape, hn1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6355, -1.2483,  0.1849,  0.4790,  0.2085],\n",
      "         [ 0.7573,  0.8759,  1.2106,  0.0069, -0.8169],\n",
      "         [ 3.6274,  1.7327,  1.2932, -1.1668,  0.9719],\n",
      "         [-1.0654,  0.5295,  0.2408, -0.7390,  0.0983]],\n",
      "\n",
      "        [[-0.1030,  0.9930,  0.3306, -0.5867, -0.6893],\n",
      "         [ 0.1868, -1.5110, -0.3317,  0.8243,  0.8216],\n",
      "         [-0.6317,  0.1180, -1.5435, -0.9352, -1.3807],\n",
      "         [ 1.4175, -1.0238, -2.0363, -0.0244, -0.2260]],\n",
      "\n",
      "        [[ 0.8135,  0.6997,  0.0050, -0.8873,  0.6621],\n",
      "         [ 1.9415, -0.1520, -0.1533, -0.7482,  1.7013],\n",
      "         [-2.4631,  0.8586,  0.7060,  0.5539,  0.1218],\n",
      "         [-1.5974,  1.9678,  0.3687,  0.6994,  0.8923]]])\n",
      "tensor([[[-1.0654,  0.5295,  0.2408, -0.7390,  0.0983],\n",
      "         [ 3.6274,  1.7327,  1.2932, -1.1668,  0.9719],\n",
      "         [ 0.7573,  0.8759,  1.2106,  0.0069, -0.8169],\n",
      "         [ 0.6355, -1.2483,  0.1849,  0.4790,  0.2085]],\n",
      "\n",
      "        [[ 1.4175, -1.0238, -2.0363, -0.0244, -0.2260],\n",
      "         [-0.6317,  0.1180, -1.5435, -0.9352, -1.3807],\n",
      "         [ 0.1868, -1.5110, -0.3317,  0.8243,  0.8216],\n",
      "         [-0.1030,  0.9930,  0.3306, -0.5867, -0.6893]],\n",
      "\n",
      "        [[-1.5974,  1.9678,  0.3687,  0.6994,  0.8923],\n",
      "         [-2.4631,  0.8586,  0.7060,  0.5539,  0.1218],\n",
      "         [ 1.9415, -0.1520, -0.1533, -0.7482,  1.7013],\n",
      "         [ 0.8135,  0.6997,  0.0050, -0.8873,  0.6621]]])\n"
     ]
    }
   ],
   "source": [
    "rnn2 = nn.RNN(5, 6, num_layers=1, batch_first=True, bidirectional=False)  # 反向rnn\n",
    "rnn2.weight_ih_l0 = rnn.weight_ih_l0_reverse\n",
    "rnn2.weight_hh_l0 = rnn.weight_hh_l0_reverse\n",
    "rnn2.bias_ih_l0 = rnn.bias_ih_l0_reverse\n",
    "rnn2.bias_hh_l0 = rnn.bias_hh_l0_reverse\n",
    "ho2, hn2 = rnn2(torch.flip(x, dims=[1]))\n",
    "ho2 = torch.flip(ho2, dims=[1])  # 还原按照实际的顺序进行排列\n",
    "print(x)\n",
    "print(torch.flip(x, dims=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "tensor([[[ 2.4997e-01, -6.5079e-01, -1.0831e-01, -3.4363e-01,  6.5327e-01,\n",
      "           3.4949e-01, -9.0123e-01, -1.3707e-01,  5.2284e-01, -7.3734e-01,\n",
      "           8.2482e-01,  8.3302e-01],\n",
      "         [-1.1522e-01, -5.8889e-01, -2.6241e-01,  2.7714e-01, -2.3205e-01,\n",
      "          -3.0220e-01, -9.2499e-01,  4.1108e-01,  8.9493e-01, -1.2808e-01,\n",
      "           7.1807e-01,  7.1384e-01],\n",
      "         [-6.7210e-01, -8.6936e-01, -2.9957e-01,  8.6866e-02,  7.8730e-01,\n",
      "          -2.9405e-01, -8.7535e-01,  9.8309e-01,  9.6490e-01,  9.5614e-01,\n",
      "          -3.3722e-01,  2.2426e-01],\n",
      "         [-6.2781e-01, -2.7431e-01,  2.7192e-01, -1.6900e-02, -6.9228e-01,\n",
      "          -6.3565e-01, -1.6193e-01,  4.1156e-02,  1.8112e-02, -1.5733e-01,\n",
      "           7.7520e-02,  5.9341e-01]],\n",
      "\n",
      "        [[-3.5992e-01, -1.0978e-01,  1.6988e-01,  7.1630e-02, -6.1059e-01,\n",
      "          -2.1763e-02, -1.6360e-01, -1.2046e-01,  5.7042e-01,  3.2563e-01,\n",
      "          -7.2687e-02,  2.4515e-01],\n",
      "         [ 3.0524e-04, -5.3361e-01, -2.7804e-01, -6.6308e-01,  5.7718e-01,\n",
      "           5.6906e-01, -8.0792e-01,  1.3287e-01, -3.6173e-02, -7.1550e-01,\n",
      "           9.0699e-01,  7.7646e-01],\n",
      "         [ 8.8870e-02, -4.9191e-01,  6.9345e-01,  8.2557e-01, -9.3702e-01,\n",
      "          -1.2907e-01, -4.6463e-01, -6.7656e-01, -9.9546e-02,  3.9137e-01,\n",
      "           3.0538e-01, -3.3201e-01],\n",
      "         [ 1.1291e-01, -7.1614e-01,  4.7478e-01, -3.0375e-01,  1.6838e-01,\n",
      "           8.2345e-01, -8.9245e-01, -2.0881e-01,  1.6303e-02,  3.6831e-01,\n",
      "           7.0160e-01,  1.9699e-01]],\n",
      "\n",
      "        [[-5.9890e-01, -7.2151e-01,  3.2312e-03,  1.8860e-01,  5.7018e-02,\n",
      "          -1.9738e-01, -9.5520e-01,  4.9641e-01,  8.4852e-01,  6.2982e-02,\n",
      "           5.5057e-02,  6.6085e-01],\n",
      "         [-6.4462e-01, -9.1922e-01, -6.9357e-02, -9.4029e-02,  6.9062e-01,\n",
      "          -2.8807e-01, -9.1585e-01,  7.4582e-01,  6.6866e-01,  5.1222e-01,\n",
      "           8.2636e-02,  5.1860e-01],\n",
      "         [-6.6457e-01,  4.0127e-01, -2.6517e-01, -5.2033e-01, -8.1504e-01,\n",
      "          -4.9210e-01, -6.9591e-01, -8.1843e-01,  4.0111e-01, -8.8605e-01,\n",
      "           3.7978e-01,  9.1331e-01],\n",
      "         [-6.8967e-01,  8.1840e-01, -4.1352e-01, -5.8965e-01, -6.9231e-01,\n",
      "           3.2604e-01, -7.4251e-01, -1.1550e-01,  7.3344e-01, -5.9898e-01,\n",
      "          -1.5467e-01,  9.2442e-01]]], grad_fn=<TransposeBackward1>)\n",
      "tensor([[[ 2.4997e-01, -6.5079e-01, -1.0831e-01, -3.4363e-01,  6.5327e-01,\n",
      "           3.4949e-01, -9.0123e-01, -1.3707e-01,  5.2284e-01, -7.3734e-01,\n",
      "           8.2482e-01,  8.3302e-01],\n",
      "         [-1.1522e-01, -5.8889e-01, -2.6241e-01,  2.7714e-01, -2.3205e-01,\n",
      "          -3.0220e-01, -9.2499e-01,  4.1108e-01,  8.9493e-01, -1.2808e-01,\n",
      "           7.1807e-01,  7.1384e-01],\n",
      "         [-6.7210e-01, -8.6936e-01, -2.9957e-01,  8.6866e-02,  7.8730e-01,\n",
      "          -2.9405e-01, -8.7535e-01,  9.8309e-01,  9.6490e-01,  9.5614e-01,\n",
      "          -3.3722e-01,  2.2426e-01],\n",
      "         [-6.2781e-01, -2.7431e-01,  2.7192e-01, -1.6900e-02, -6.9228e-01,\n",
      "          -6.3565e-01, -1.6193e-01,  4.1156e-02,  1.8112e-02, -1.5733e-01,\n",
      "           7.7520e-02,  5.9341e-01]],\n",
      "\n",
      "        [[-3.5992e-01, -1.0978e-01,  1.6988e-01,  7.1630e-02, -6.1059e-01,\n",
      "          -2.1763e-02, -1.6360e-01, -1.2046e-01,  5.7042e-01,  3.2563e-01,\n",
      "          -7.2687e-02,  2.4515e-01],\n",
      "         [ 3.0524e-04, -5.3361e-01, -2.7804e-01, -6.6308e-01,  5.7718e-01,\n",
      "           5.6906e-01, -8.0792e-01,  1.3287e-01, -3.6173e-02, -7.1550e-01,\n",
      "           9.0699e-01,  7.7646e-01],\n",
      "         [ 8.8870e-02, -4.9191e-01,  6.9345e-01,  8.2557e-01, -9.3702e-01,\n",
      "          -1.2907e-01, -4.6463e-01, -6.7656e-01, -9.9546e-02,  3.9137e-01,\n",
      "           3.0538e-01, -3.3201e-01],\n",
      "         [ 1.1291e-01, -7.1614e-01,  4.7478e-01, -3.0375e-01,  1.6838e-01,\n",
      "           8.2345e-01, -8.9245e-01, -2.0881e-01,  1.6303e-02,  3.6831e-01,\n",
      "           7.0160e-01,  1.9699e-01]],\n",
      "\n",
      "        [[-5.9890e-01, -7.2151e-01,  3.2312e-03,  1.8860e-01,  5.7018e-02,\n",
      "          -1.9738e-01, -9.5520e-01,  4.9641e-01,  8.4852e-01,  6.2982e-02,\n",
      "           5.5057e-02,  6.6085e-01],\n",
      "         [-6.4462e-01, -9.1922e-01, -6.9357e-02, -9.4029e-02,  6.9062e-01,\n",
      "          -2.8807e-01, -9.1585e-01,  7.4582e-01,  6.6866e-01,  5.1222e-01,\n",
      "           8.2636e-02,  5.1860e-01],\n",
      "         [-6.6457e-01,  4.0127e-01, -2.6517e-01, -5.2033e-01, -8.1504e-01,\n",
      "          -4.9210e-01, -6.9591e-01, -8.1843e-01,  4.0111e-01, -8.8605e-01,\n",
      "           3.7978e-01,  9.1331e-01],\n",
      "         [-6.8967e-01,  8.1840e-01, -4.1352e-01, -5.8965e-01, -6.9231e-01,\n",
      "           3.2604e-01, -7.4251e-01, -1.1550e-01,  7.3344e-01, -5.9898e-01,\n",
      "          -1.5467e-01,  9.2442e-01]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "       grad_fn=<SubBackward0>)\n",
      "====================================================================================================\n",
      "tensor([[[-0.6278, -0.2743,  0.2719, -0.0169, -0.6923, -0.6357],\n",
      "         [ 0.1129, -0.7161,  0.4748, -0.3038,  0.1684,  0.8235],\n",
      "         [-0.6897,  0.8184, -0.4135, -0.5897, -0.6923,  0.3260]],\n",
      "\n",
      "        [[-0.9012, -0.1371,  0.5228, -0.7373,  0.8248,  0.8330],\n",
      "         [-0.1636, -0.1205,  0.5704,  0.3256, -0.0727,  0.2451],\n",
      "         [-0.9552,  0.4964,  0.8485,  0.0630,  0.0551,  0.6609]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.6278, -0.2743,  0.2719, -0.0169, -0.6923, -0.6357],\n",
      "         [ 0.1129, -0.7161,  0.4748, -0.3038,  0.1684,  0.8235],\n",
      "         [-0.6897,  0.8184, -0.4135, -0.5897, -0.6923,  0.3260]],\n",
      "\n",
      "        [[-0.9012, -0.1371,  0.5228, -0.7373,  0.8248,  0.8330],\n",
      "         [-0.1636, -0.1205,  0.5704,  0.3256, -0.0727,  0.2451],\n",
      "         [-0.9552,  0.4964,  0.8485,  0.0630,  0.0551,  0.6609]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0.]]], grad_fn=<SubBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n",
      "tensor(0., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ho_ = torch.concat([ho1, ho2], dim=2)\n",
    "hn_ = torch.concat([hn1, hn2], dim=0)\n",
    "print(\"=\" * 100)\n",
    "print(ho)\n",
    "print(ho_)\n",
    "print(ho - ho_)\n",
    "print(\"=\" * 100)\n",
    "print(hn)\n",
    "print(hn_)\n",
    "print(hn - hn_)\n",
    "print(torch.mean(torch.abs(ho - ho_)))\n",
    "print(torch.mean(torch.abs(hn - hn_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([6, 5])\n",
      "weight_hh_l0 torch.Size([6, 6])\n",
      "bias_ih_l0 torch.Size([6])\n",
      "bias_hh_l0 torch.Size([6])\n",
      "weight_ih_l0_reverse torch.Size([6, 5])\n",
      "weight_hh_l0_reverse torch.Size([6, 6])\n",
      "bias_ih_l0_reverse torch.Size([6])\n",
      "bias_hh_l0_reverse torch.Size([6])\n",
      "weight_ih_l1 torch.Size([6, 12])\n",
      "weight_hh_l1 torch.Size([6, 6])\n",
      "bias_ih_l1 torch.Size([6])\n",
      "bias_hh_l1 torch.Size([6])\n",
      "weight_ih_l1_reverse torch.Size([6, 12])\n",
      "weight_hh_l1_reverse torch.Size([6, 6])\n",
      "bias_ih_l1_reverse torch.Size([6])\n",
      "bias_hh_l1_reverse torch.Size([6])\n",
      "weight_ih_l2 torch.Size([6, 12])\n",
      "weight_hh_l2 torch.Size([6, 6])\n",
      "bias_ih_l2 torch.Size([6])\n",
      "bias_hh_l2 torch.Size([6])\n",
      "weight_ih_l2_reverse torch.Size([6, 12])\n",
      "weight_hh_l2_reverse torch.Size([6, 6])\n",
      "bias_ih_l2_reverse torch.Size([6])\n",
      "bias_hh_l2_reverse torch.Size([6])\n",
      "weight_ih_l3 torch.Size([6, 12])\n",
      "weight_hh_l3 torch.Size([6, 6])\n",
      "bias_ih_l3 torch.Size([6])\n",
      "bias_hh_l3 torch.Size([6])\n",
      "weight_ih_l3_reverse torch.Size([6, 12])\n",
      "weight_hh_l3_reverse torch.Size([6, 6])\n",
      "bias_ih_l3_reverse torch.Size([6])\n",
      "bias_hh_l3_reverse torch.Size([6])\n",
      "torch.Size([3, 4, 12])\n",
      "torch.Size([8, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(5, hidden_size=6, num_layers=4, batch_first=True, bidirectional=True)\n",
    "for name, param in rnn.named_parameters():\n",
    "    print(name, param.shape)\n",
    "x = torch.rand(3, 4, 5)\n",
    "ho, hs = rnn(x)\n",
    "print(ho.shape)  # 最后一层每个时刻的输出值[n,t,2*hidden_size]\n",
    "print(hs.shape)  # 每一层每个方向的RNN的最后一个时刻的状态信息# [(2 if bidirectional else 1) * num_layers, N, hidden_size]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ait",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
